tmp2 = tmp2[order(tmp2)]
tmp1[1]
tmp2[1]
length(tmp1)
length(tmp2)
sum(tmp1[1:15653] == tmp2[1:15653])
tmp1[13427:13428]
tmp1[13427:13429]
tmp2[13427:13429]
tmp1[13425:13429]
tmp2[13425:13429]
pvalueData[1,]
pvalueData[pvalueData[,3]==19549972, ]
pvalueData2[pvalueData2[,3]=="19549972", ]
pvalueData2[pvalueData2[,3]=="19549973", ]
tmp2[13425:13429]
tmp2[13424:13429]
tmp1[13424:13429]
sum(tmp1[1:13424] == tmp2[1:13424])
sum(tmp1[1:11940] == tmp2[1:11940])
plot(tmp1,tmp2)
length(tmp2)
plot(tmp1,tmp2[1:15653])
t1 = table(tmp1)
t2 = table(tmp2)
t1[1]
t2[1]
sum(t1 == t2)
length(t2)
length(t1)
setdiff(names(t1),names(t2))
sum(t1 == t2[1:5323])
oo = match(names(t1),names(t2))
length(oo)
oo[1]
oo = match(names(t2),names(t1))
length(oo)
sum(is.na(oo))
which(is.na(oo))
length(names(t2))
t2[3097]
sum(t2)
dim(pvalueData)
dim(pvalueData2)
pvalueData2[pvalueData2[,3]=="16421237",]
pvalueData3 = pvalueData2[-which(pvalueData2[,3]=="16421237"),]
dim(pvalueData3)
dim(pvalueData)
tmp1 = pvalueData3[,3]
tmp2 = pvalueData[,3]
length(tmp1)
length(tmp2)
tmp1[1]
tmp2[1]
tmp1 = as.numeric(tmp1)
tmp1 = tmp1[order(tmp1)]
tmp2 = tmp2[order(tmp2)]
tmp1[1]
tmp2[1]
plot(tmp1,tmp2)
sum(tmp1==tmp2)
mean(tmp1==tmp2)
tmp1 = pvalueData3[,3]#
tmp2 = pvalueData[,3]
tmp1[1]
tmp1 = as.numeric(tmp1)
colnames(pvalueData3)
pvals1 = as.numeric(pvalueData3[,1])
pvals2 = as.numeric(pvalueData[,1])
pvals1[1]
pvals2[1]
pvals1 = pvals1[order(tmp1)]
pvals2 = pvals1[order(tmp2)]
sum(pvals1==pvals2)
length(pvals1)
ne = which(pvals1!=pvals2)
ne[1]
pvals1 = as.numeric(pvalueData3[,1])
pvals2 = as.numeric(pvalueData[,1])
pvals1 = pvals1[order(tmp1)]
pvals2 = pvals2[order(tmp2)]
sum(pvals1==pvals2)
length(pvals1)
mean(pvals1==pvals2)
mean((pvals1 - pvals2) < 1e-3)
mean((pvals1 - pvals2) < 1e-5)
mean(abs(pvals1 - pvals2) < 1e-5 )
dim(pvalueData)
dim(pvalueData3)
rm(list=ls())
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueDataTest.rda")
dim(pvalueData)
rm(list=ls())
pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueDataTest.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueDataTest.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueData.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}#
## These come from the paper Pubmed ID = 20876667 and are reports from## a GWAS. Update some P-values that are incorrectly scraped because of## variation in scientific notation.pvalueData[pvalueData[,1] == 10,1] = 10e-7pvalueData = pvalueData[-1,]## These come from the Lancet, with missed periods in the P-valuespvalueData[13392,1] = 0.003pvalueData[13413,1] = 0.014pvalueData[13414,1] = 0.004## This one comes from the Lancet too, where an incorrect P-value is grabbed.pvalueData = pvalueData[-14674,]#
# Remove rows with P-values that are pvalueData = pvalueData[!is.na(pvalueData[,1]),]# This one for some reason replaced a period with "small middle dot"pvalueData[which(pvalueData[,3] == 11943262),1] = 1e-4# This one has a <<< in the P-value definitionpvalueData = pvalueData[-which(pvalueData[,3]=="16421237"),] #
save(pvalueData,npapers,file="pvalueData.rda")
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1
]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]
?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}#
## Run the above functions over a specified set of journals and years## to obtain P-values#
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}
Functions to scrape P-values from Pubmed abstracts# Date: 7-1-12# Copyright (C) 2011 Jeffrey T. Leek (http://www.biostat.jhsph.edu/~jleek/contact.html) and Leah R. Jager##    This program is free software: you can redistribute it and/or modify#    it under the terms of the GNU General Public License as published by#    the Free Software Foundation, either version 3 of the License, or#    (at your option) any later version.##    This program is distributed in the hope that it will be useful,#    but WITHOUT ANY WARRANTY; without even the implied warranty of#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the#    GNU General Public License for more details, see <http://www.gnu.org/licenses/>.###    Note: These functions were written on a Mac and may have difficulties when#          read on windows machines. ##########################################################################################
library(RCurl)library(XML)library(tm)#
# A function to get all abstracts and pubmed ids for papers from the journal "journaltitle" in the year "year"# by scraping the Pubmed API.getAbstractsPmids = function(journaltitle,year){# esearchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?"q = paste("db=pubmed&term=",gsub(" ","+",journaltitle),"[ta]+AND+",year,"[dp]&usehistory=y",sep="")esearch <- xmlTreeParse(getURL(paste(url, q, sep="")), useInternal = T)webenv  <- xmlValue(getNodeSet(esearch, "//WebEnv")[[1]])key     <- xmlValue(getNodeSet(esearch, "//QueryKey")[[1]])# efetchurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?"q   <- "db=pubmed&retmode=xml&rettype=abstract"efetch <- xmlTreeParse(getURL(paste(url, q, "&WebEnv=", webenv, "&query_key=", key, sep="")), useInternal = T)r = xmlRoot(efetch)n = xmlSize(r)abstracts = pmid = titles = rep(NA,n)for(i in 1:n){abstracts[i] =  xmlValue(r[[i]][[1]][["Article"]][["Abstract"]]); pmid[i] = xmlValue(r[[i]][[1]][["PMID"]]); titles[i] = xmlValue(r[[i]][[1]][["Article"]][["ArticleTitle"]]) }return(list(abstracts=abstracts,pmid=pmid,titles=titles))}#
#A function to remove trailing zeros from the P-value stringsremoveTrailing = function(string){  while(length(grep("[0-9]",strsplit(string,"")[[1]][nchar(string)])) == 0){    string = substr(string,1,(nchar(string)-1))  }  return(string)}#
# A function to convert the scientific notation used by journals into# numeric values that can be analyzed. convertScientific = function(string){  if(length(grep("[[:punct:]][[:space:]]",string))>0){    string = strsplit(string,"[[:punct:]][[:space:]]")[[1]][1]    string = removeTrailing(string)  }  if(length(grep("[×x]",string))>0){    string = gsub("[:space:]","",string)    tmp1 = as.numeric(strsplit(string,"[×x]")[[1]][1])    tmp2 = as.numeric(strsplit(strsplit(string,"[×x]")[[1]][2],"[−-]")[[1]][2])    return(tmp1*10^(-tmp2))  }else{    return(as.numeric(string))  }}#
# A function to scrape the P-values from a vector of abstracts with corresponding# pubmed idsgetPvalues = function(abstract,pmid){  pvalues = numeric(0)  trunc = numeric(0)  ids = numeric(0)  # Get the truncated p-values  ind = grep("[Pp][[:space:]]?[<≤]",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?[<≤]")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,1)        ids = c(ids,pmid[ind[i]])      }    }  }   # Get the truncated p-values  ind = grep("[Pp][[:space:]]?=",abstract)  for(i in 1:length(ind)){    tmp = strsplit(abstract[ind[i]],"[[:space:](][Pp][[:space:]]?=")[[1]]    n = length(tmp)    for(j in 1:n){      if(length(grep("[.0123456789]",substr(tmp[j],1,2))) > 0){        if(length(grep("[A-Z]",substr(tmp[j],1,1)))>0){next;}        tmp2 = strsplit(tmp[j],"[^[:punct:][:space:][:digit:]x[:space:]]")[[1]][1]        tmp2 = removeTrailing(tmp2)        tmp2 = gsub(" ","",tmp2)        tmp2 = convertScientific(tmp2)        pvalues = c(pvalues,as.numeric(tmp2))        trunc = c(trunc,0)        ids = c(ids,pmid[ind[i]])      }    }  }  return(list(pvalues=pvalues,ids=ids,trunc=trunc))}
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}
tmpData
i
j
tmpData = getAbstractsPmids(journals[i],years[j])
while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")
journals = c("JAMA","New England Journal of Medicine","BMJ","American Journal of Epidemiology","Lancet")years = 2000:2010pvalueData = matrix(NA,nrow=1,ncol=6)colnames(pvalueData) = c("pvalue","pvalueTruncated","pubmedID","year","abstract","title")npapers = matrix(NA,nrow=length(journals),ncol=length(years))for(i in 1:length(journals)){  for(j in 1:length(years)){    cat(journals[i]); cat(" "); cat(years[j]); cat(" ");     tmpData = getAbstractsPmids(journals[i],years[j])    while(length(tmpData$abstracts) ==1 & is.na(tmpData$abstracts[1])){tmpData = getAbstractsPmids(journals[i],years[j])}    cat("Downloaded"); cat(" ");    npapers[i,j] = length(tmpData$abstracts)    tmpOut = getPvalues(tmpData$abstracts,tmpData$pmid)#
nPvalues = length(tmpOut$pvalues)    aa = match(tmpOut$ids,tmpData$pmid)#
tmpMatrix = cbind(tmpOut$pvalues,tmpOut$trunc,as.numeric(tmpOut$ids),rep(years[j],nPvalues),tmpData$abstracts[aa],tmpData$titles[aa])    rownames(tmpMatrix) = rep(journals[i],nPvalues)    pvalueData = rbind(pvalueData,tmpMatrix)    cat("Done\n")  }}
barplot(c(1,1,-3))
?barplot
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12[1,]
pres08 = read.csv("~/Desktop/2008pres.csv")
pres08[1,]
sum(pres12$FIPS == 0)
table(pres12$X[pres12$FIPS==0,])
table(pres12$X[pres12$FIPS==0])
pres12[pres12$X=="OK",]
pres12 = pres12[pres12$FIPS==0,]
dim(pres12)
pres12[1,]
pres12[2,]
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12[1:10,]
pres12[21:30,]
pres12[50:100,]
pres12 = pres12[pres12$FIPS==0,]
length(unique(pres12$X))
which.max(pres12$X == "OK")
which(pres12$X == "OK")
pres12[c(36,37)]
pres12[c(36,37),]
pres12[1,]
pres12[1,5]
pres12[1,4]
as.numeric(pres12[1,4])
as.numeric(as.character(pres12[1,4])
)
as.numeric(as.character(pres12[1,4]))
pres08[1,]
sum(pres08$LAST.NAME == "McCain")
sum(pres08$LAST.NAME == "McCain" & pres08$STATE=="Alabama")
pres08[pres08$LAST.NAME == "McCain",]
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12 = pres12[pres12$FIPS==0,]
pres12[1,]
table(unique(pres12))
table(unique(pres12$x))
table(unique(pres12$X))
substr
gsub
gsub(pres12[1,3])
pres12[1,]
pres12$Obama.vote[1]
dem12 = as.character(pres12$Obama.vote)
dem12[1]
dem12 = sapply(dem12,function(x){gsub(x,",","")})
dem12[1]
dem12 = as.character(pres12$Obama.vote)
gsub(dem12[1],",","")
?gsub
gsub(",","",dem12[1])
dem12 = as.character(pres12$Obama.vote)
dem12 = as.numeric(sapply(dem12,function(x){gsub(",","",x)}))
dem12[1]
hist(dem12)
pres12 = read.csv("~/Desktop/2012-pres.csv")
pres12 = pres12[pres12$FIPS==0,]
dem12 = as.character(pres12$Obama.vote)
dem12 = as.numeric(sapply(dem12,function(x){gsub(",","",x)}))
rep12 = as.character(pres12$Romney.vote)
rep12 = as.numeric(sapply(rep12,function(x){gsub(",","",x)}))
plot(rep12,dem12)
rep12[1]
pres12[1,]
table(pres12[,2])
res12 = read.csv("~/Desktop/2012-pres.csv")
pres12 = pres12[pres12$FIPS==0,]
table(pres12[,2])
table(pres12[,1])
library(XML)
theurl <- "http://uselectionatlas.org/RESULTS/data.php?year=2008&datatype=national&def=1&f=0&off=0&elect=0"
tables <- readHTMLTable(theurl)
tables[1,]
dim(tables)
tables[1]
tables
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
n.rows
library(slidify)
?author
setwd("~/Documents/Work/teaching/2013/coursera/")
ls()
list.files()
author("gettingStarted")
slidify("gettingStarted")
ls()
list.files()
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
setwd("~/Documents/Work/teaching/2013/coursera/")
setwd("gettingHelp/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
getwd()
setwd("../aboutDataAnalysis/")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
setwd("~/Dropbox/Jeff/teaching/2013/")
setwd("753/lectures/")
setwd("001courseMotivation/")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
setwd("~/Dropbox/Jeff/teaching/2013/753/jhsph753/lectures/001courseMotivation/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
setwd("~/Dropbox/Jeff/teaching/2013/753/jhsph753/intros/004intro/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
library(XML)
?htmlParseTree
?htmlTreeParse
tree
espn <- xmlTreeParse("http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens")
espn
espn <- xmlTreeParse("http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens")
?xmlTreeParse
espn <- xmlTreeParse("http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens",useInternalNodes=TRUE)
espn <- htmlTreeParse("http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens",useInternalNodes=TRUE)
espn[1]
class(expn)
class(espn)
setwd('~/Dropbox/Jeff/teaching/2013/753/jhsph753/intros/')
setwd("005intro/intro/")
setwd("005intro/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
setwd("~/Dropbox/Jeff/teaching/2013/753/")
list.files()
setwd("jhsph753/intros/006intro/")
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
browseURL("index.html")
hist(rcauchy(100))
hist(rcauchy(100))
hist(rcauchy(100))
hist(rcauchy(100))
hist(rcauchy(100))
hist(rnorm(100))
plot(jitter(rep(1,100)),rnorm(100))
plot(jitter(rep(1,100)),rnorm(100),xlim=c(0,1),xaxt="n")
plot(jitter(rep(1,100)),rnorm(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rcauchy(100),xlim=c(0.5,1.5),xaxt="n")
plot(jitter(rep(1,100)),rf(100,1,10),xlim=c(0.5,1.5),xaxt="n")
library(XML)
htmlRaven=htmlTreeParse("http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens",useInternalNodes=TRUE)
## Choose the list items with class='score' ##
Score=xpathSApply(htmlRaven,"//li[@class='score']",xmlValue)
## Choose the list items with class='team-name' ##
TeamName=xpathSApply(htmlRaven,"//li[@class='team-name']",xmlValue)
## Choose the whole unordered list with class='score' ##
WinLoss=xpathSApply(htmlRaven,"//ul[@class='game-schedule']//span",xmlValue)
## This is tricky ##
## First get all the //td items under the rows(//tr) whose @class contains 'row' ##
## Choose those which contains ',', which are the actual dates ##
## There is no class or id under the date component. I had to do this. ##
Date=grep(',',xpathSApply(htmlRaven,"//tr[contains(@class,'row')]//td",xmlValue),value=TRUE)
## Combine the data ##
RavenData=data.frame(date=Date,team=TeamName,status=WinLoss,score=Score)
RavenData
ls()
RavenData[1,]
x <- cbind(rep(1,10),rnorm(10))
b <- c(1,2)
y <- rnorm(10)
t(b) %*% t(x)
t(b) %*% t(x) %*% y
getwd(
)
slidify("index.Rmd")
x
y
lm(y ~ x)
library(sandwich)
install.packages("sandwich")
library(sandwich)
lm1 <- lm(y ~ x)
lm1
y
x1
x
x <- x[,1]
lm(y ~ x)
x <- rnorm(10)
lm(y ~ x)
lm1 <- lm(y ~ x)
vcovH(lm1,"HC0")
library(sandwich)
?vcovH
?vcovHC
vcovHC(lm1)
summary(lm1)
sqrt(vcovHC(lm1))
X <- cbind(rep(1,10),x)
solve(t(X)%*%X)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% solve(t(X)%*%X)%*t(X)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% solve(t(X)%*%X)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% solve(t(X)%*%X)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*%
)
dim(solve(t(X)%*%X))
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% solve(t(X) %*% X)
solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% solve(t(X) %*% X)
dim(solve(t(X)%*%X) %*% t(X)%*%(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff))
t(y - X %*% lm1$coeff)) %*% solve(t(X) %*% X)
t(y - X %*% lm1$coeff) %*% solve(t(X) %*% X)
dim(solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)) %*% X
dim(solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)) %*% t(X)
dim(t(y - X %*% lm1$coeff))
dim(t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff))
dim(solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)) %*% X %*% solve(t(X)%*%X)
dim(solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)) %*% t(X) %*% solve(t(X)%*%X)
t(y - X %*% lm1$coeff)
t(y - X %*% lm1$coeff) %*% X
dim(solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)) %*% X %*% solve(t(X)%*%X)
dim(solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)) %*% X
solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% X
solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% X %*% solve(t(X)%*% X)
(y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff)
solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)%*%t(y - X %*% lm1$coeff) %*% X %*% solve(t(X)%*% X)
solve(t(X)%*%X) %*% t(X)%*% (y - X%*%lm1$coeff)
t((y - X%*%lm1$coeff)) %*% (y - X%*%lm1$coeff)
t((y - X%*%lm1$coeff))
t((y - X%*%lm1$coeff)) %*% (y - X%*%lm1$coeff)
(y - X%*%lm1$coeff) %*% t(y - X%*%lm1$coeff)
(y - X%*%lm1$coeff) %*% t(y - X%*%lm1$coeff) %*% X
